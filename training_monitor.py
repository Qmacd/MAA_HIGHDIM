"""
Training monitoring and visualization system
Record all key metrics during training and generate charts
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
import json
from datetime import datetime
import seaborn as sns
from collections import defaultdict
import torch
from tqdm import tqdm  # æ·»åŠ tqdmè¿›åº¦æ¡

class TrainingMonitor:
    """è®­ç»ƒç›‘æ§å™¨ - è®°å½•å’Œå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹"""
    
    def __init__(self, experiment_name, save_dir="training_logs", asset_name=None, task_mode=None, fusion_mode=None, strategy=None):
        self.experiment_name = experiment_name
        self.save_dir = save_dir
        self.log_file = os.path.join(save_dir, f"{experiment_name}_training_log.json")
        
        # å®éªŒå…ƒä¿¡æ¯
        self.asset_name = asset_name or "Unknown"
        self.task_mode = task_mode or "Unknown"
        self.fusion_mode = fusion_mode or "Unknown"
        self.strategy = strategy or "Unknown"
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        
        # åˆå§‹åŒ–è®°å½•å­—å…¸
        self.metrics = defaultdict(list)
        self.epoch_times = []
        self.learning_rates = []
        self.start_time = None
        
        # è®¾ç½®matplotlibå­—ä½“ï¼Œè§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
        self._use_english_labels = False
        try:
            # å°è¯•è®¾ç½®æ”¯æŒä¸­æ–‡çš„å­—ä½“
            import matplotlib
            matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
            
            if os.name == 'nt':  # Windowsç³»ç»Ÿ
                fonts = ['Microsoft YaHei', 'SimHei', 'KaiTi', 'FangSong']
            else:  # Linux/Unixç³»ç»Ÿ  
                fonts = ['WenQuanYi Micro Hei', 'DejaVu Sans', 'Liberation Sans']
            
            # å°è¯•æ¯ä¸ªå­—ä½“
            for font in fonts:
                try:
                    plt.rcParams['font.sans-serif'] = [font] + plt.rcParams['font.sans-serif']
                    plt.rcParams['axes.unicode_minus'] = False
                    
                    # æµ‹è¯•ä¸­æ–‡å­—ç¬¦æ¸²æŸ“
                    fig, ax = plt.subplots(figsize=(1, 1))
                    ax.text(0.5, 0.5, 'æµ‹è¯•', fontsize=8)
                    fig.canvas.draw()
                    plt.close(fig)
                    
                    print(f"[INFO] Chinese font '{font}' successfully configured")
                    break
                except Exception as font_error:
                    print(f"[DEBUG] Font '{font}' failed: {font_error}")
                    continue
            else:
                # æ‰€æœ‰ä¸­æ–‡å­—ä½“éƒ½å¤±è´¥ï¼Œä½¿ç”¨è‹±æ–‡
                raise Exception("No Chinese fonts available")
                
        except Exception as e:
            # å¦‚æœå­—ä½“è®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“å¹¶è®¾ç½®ä¸ºè‹±æ–‡
            plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial', 'sans-serif']
            plt.rcParams['axes.unicode_minus'] = False
            print(f"[Warning] Chinese font setup failed: {e}, using English labels")
            self._use_english_labels = True
        
        print(f"[INFO] Training monitor started: {experiment_name}")
        print(f"[INFO] Log save path: {self.log_file}")
        print(f"[INFO] Experiment config: {self.asset_name}|{self.task_mode}|{self.fusion_mode}|{self.strategy}")
    
    def get_file_prefix(self):
        """ç”Ÿæˆå¸¦å®éªŒä¿¡æ¯çš„æ–‡ä»¶å‰ç¼€"""
        return f"{self.asset_name}_{self.task_mode}_{self.fusion_mode}_{self.strategy}"
    
    def start_epoch(self):
        """å¼€å§‹ä¸€ä¸ªepoch"""
        self.start_time = datetime.now()
    
    def end_epoch(self, epoch, optimizer=None):
        """ç»“æŸä¸€ä¸ªepoch"""
        if self.start_time:
            epoch_time = (datetime.now() - self.start_time).total_seconds()
            self.epoch_times.append(epoch_time)
            
        # è®°å½•å­¦ä¹ ç‡
        if optimizer:
            current_lr = optimizer.param_groups[0]['lr']
            self.learning_rates.append(current_lr)
        
        # ä¿å­˜æ—¥å¿—
        self.save_log()
        
        # æ¯10ä¸ªepochç”Ÿæˆä¸€æ¬¡å›¾è¡¨
        if (epoch + 1) % 10 == 0:
            self.plot_training_curves()
    
    def log_loss(self, phase, loss_type, value, epoch):
        """è®°å½•æŸå¤±"""
        key = f"{phase}_{loss_type}"
        self.metrics[key].append({'epoch': epoch, 'value': float(value)})
    
    def log_metric(self, phase, metric_name, value, epoch):
        """è®°å½•è¯„ä¼°æŒ‡æ ‡"""
        key = f"{phase}_{metric_name}"
        self.metrics[key].append({'epoch': epoch, 'value': float(value)})
    
    def log_maa_metrics(self, phase, generator_acc, discriminator_acc, epoch):
        """è®°å½•MAAç‰¹å®šæŒ‡æ ‡"""
        self.log_metric(phase, 'generator_accuracy', generator_acc, epoch)
        self.log_metric(phase, 'discriminator_accuracy', discriminator_acc, epoch)
    
    def log_correlation(self, phase, correlation, epoch):
        """è®°å½•é¢„æµ‹ç›¸å…³æ€§"""
        self.log_metric(phase, 'correlation', correlation, epoch)
    
    def log_sharpe_ratio(self, phase, sharpe, epoch):
        """è®°å½•å¤æ™®æ¯”ç‡"""
        self.log_metric(phase, 'sharpe_ratio', sharpe, epoch)
    
    def save_log(self):
        """ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶"""
        # ç¡®ä¿æ—¥å¿—æ–‡ä»¶çš„ç›®å½•å­˜åœ¨
        log_dir = os.path.dirname(self.log_file)
        if log_dir and not os.path.exists(log_dir):
            os.makedirs(log_dir, exist_ok=True)
            
        log_data = {
            'experiment_name': self.experiment_name,
            'timestamp': datetime.now().isoformat(),
            'metrics': dict(self.metrics),
            'epoch_times': self.epoch_times,
            'learning_rates': self.learning_rates
        }
        
        with open(self.log_file, 'w', encoding='utf-8') as f:
            json.dump(log_data, f, indent=2, ensure_ascii=False)
    
    def plot_training_curves(self):
        """ç”Ÿæˆè®­ç»ƒæ›²çº¿å›¾"""
        if not self.metrics:
            return
        
        # åˆ›å»ºå›¾è¡¨ç›®å½•
        plot_dir = os.path.join(self.save_dir, "plots")
        os.makedirs(plot_dir, exist_ok=True)
        
        # åˆ›å»ºå®éªŒç‰¹å®šçš„å­ç›®å½•
        exp_plot_dir = os.path.join(plot_dir, self.get_file_prefix())
        os.makedirs(exp_plot_dir, exist_ok=True)
        
        # 1. æŸå¤±æ›²çº¿
        self._plot_losses(exp_plot_dir)
        
        # 2. å‡†ç¡®ç‡/ç›¸å…³æ€§æ›²çº¿
        self._plot_accuracies(exp_plot_dir)
        
        # 3. MAAç‰¹å®šæŒ‡æ ‡
        self._plot_maa_metrics(exp_plot_dir)
        
        # 4. å­¦ä¹ ç‡å’Œè®­ç»ƒæ—¶é—´
        self._plot_training_stats(exp_plot_dir)
        
        # 5. ç»¼åˆå¯¹æ¯”å›¾
        self._plot_comprehensive_comparison(exp_plot_dir)
        
        print(f"[INFO] Training plots saved to: {exp_plot_dir}")
    
    def _plot_losses(self, plot_dir):
        """ç»˜åˆ¶æŸå¤±æ›²çº¿"""
        loss_keys = [k for k in self.metrics.keys() if 'loss' in k.lower()]
        if not loss_keys:
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle(f'{self.experiment_name} - Loss Curves', fontsize=16, fontweight='bold')
        
        # è®­ç»ƒæŸå¤±
        train_losses = [k for k in loss_keys if 'train' in k]
        if train_losses:
            ax = axes[0, 0]
            for loss_key in train_losses:
                data = self.metrics[loss_key]
                epochs = [d['epoch'] for d in data]
                values = [d['value'] for d in data]
                ax.plot(epochs, values, label=loss_key.replace('train_', ''), linewidth=2)
            ax.set_title('Training Loss', fontweight='bold')
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Loss')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # éªŒè¯æŸå¤±
        val_losses = [k for k in loss_keys if 'val' in k]
        if val_losses:
            ax = axes[0, 1]
            for loss_key in val_losses:
                data = self.metrics[loss_key]
                epochs = [d['epoch'] for d in data]
                values = [d['value'] for d in data]
                ax.plot(epochs, values, label=loss_key.replace('val_', ''), linewidth=2)
            ax.set_title('Validation Loss', fontweight='bold')
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Loss')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # è®­ç»ƒvséªŒè¯å¯¹æ¯”
        if train_losses and val_losses:
            ax = axes[1, 0]
            # é€‰æ‹©ä¸»è¦æŸå¤±è¿›è¡Œå¯¹æ¯”
            main_train = next((k for k in train_losses if 'total' in k or 'main' in k), train_losses[0])
            main_val = next((k for k in val_losses if 'total' in k or 'main' in k), val_losses[0])
            
            train_data = self.metrics[main_train]
            val_data = self.metrics[main_val]
            
            train_epochs = [d['epoch'] for d in train_data]
            train_values = [d['value'] for d in train_data]
            val_epochs = [d['epoch'] for d in val_data]
            val_values = [d['value'] for d in val_data]
            
            ax.plot(train_epochs, train_values, label='Training', linewidth=2, color='blue')
            ax.plot(val_epochs, val_values, label='Validation', linewidth=2, color='red')
            ax.set_title('Training vs Validation Loss', fontweight='bold')
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Loss')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # æŸå¤±ä¸‹é™è¶‹åŠ¿
        ax = axes[1, 1]
        if train_losses:
            main_loss = train_losses[0]
            data = self.metrics[main_loss]
            epochs = [d['epoch'] for d in data]
            values = [d['value'] for d in data]
            
            # è®¡ç®—ç§»åŠ¨å¹³å‡
            if len(values) > 5:
                window = min(10, len(values) // 3)
                ma_values = pd.Series(values).rolling(window=window).mean()
                ax.plot(epochs, values, alpha=0.5, label='Raw', color='lightblue')
                ax.plot(epochs, ma_values, label=f'Moving Average({window})', linewidth=2, color='darkblue')
            else:
                ax.plot(epochs, values, label='Loss Trend', linewidth=2)
            
            ax.set_title('Loss Trend', fontweight='bold')
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Loss')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(plot_dir, f'{self.get_file_prefix()}_losses.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_accuracies(self, plot_dir):
        """ç»˜åˆ¶å‡†ç¡®ç‡å’Œç›¸å…³æ€§æ›²çº¿"""
        acc_keys = [k for k in self.metrics.keys() if any(x in k.lower() for x in ['accuracy', 'correlation', 'sharpe'])]
        if not acc_keys:
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle(f'{self.experiment_name} - Performance Metrics', fontsize=16, fontweight='bold')
        
        # å‡†ç¡®ç‡
        accuracy_keys = [k for k in acc_keys if 'accuracy' in k]
        if accuracy_keys:
            ax = axes[0, 0]
            for acc_key in accuracy_keys:
                data = self.metrics[acc_key]
                epochs = [d['epoch'] for d in data]
                values = [d['value'] for d in data]
                ax.plot(epochs, values, label=acc_key, linewidth=2, marker='o', markersize=3)
            ax.set_title('Accuracy Changes', fontweight='bold')
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Accuracy')
            ax.legend()
            ax.grid(True, alpha=0.3)
            ax.set_ylim([0, 1])
        
        # ç›¸å…³æ€§
        corr_keys = [k for k in acc_keys if 'correlation' in k]
        if corr_keys:
            ax = axes[0, 1]
            for corr_key in corr_keys:
                data = self.metrics[corr_key]
                epochs = [d['epoch'] for d in data]
                values = [d['value'] for d in data]
                ax.plot(epochs, values, label=corr_key, linewidth=2, marker='s', markersize=3)
            ax.set_title('Prediction Correlation', fontweight='bold')
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Correlation')
            ax.legend()
            ax.grid(True, alpha=0.3)
            ax.set_ylim([-1, 1])
            ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)
        
        # å¤æ™®æ¯”ç‡
        sharpe_keys = [k for k in acc_keys if 'sharpe' in k]
        if sharpe_keys:
            ax = axes[1, 0]
            for sharpe_key in sharpe_keys:
                data = self.metrics[sharpe_key]
                epochs = [d['epoch'] for d in data]
                values = [d['value'] for d in data]
                ax.plot(epochs, values, label=sharpe_key, linewidth=2, marker='^', markersize=3)
            ax.set_title('Sharpe Ratio', fontweight='bold')
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Sharpe Ratio')
            ax.legend()
            ax.grid(True, alpha=0.3)
            ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)
        
        # ç»¼åˆé›·è¾¾å›¾
        ax = axes[1, 1]
        self._plot_performance_radar(ax)
        
        plt.tight_layout()
        plt.savefig(os.path.join(plot_dir, f'{self.get_file_prefix()}_performance.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_maa_metrics(self, plot_dir):
        """ç»˜åˆ¶MAAç‰¹å®šæŒ‡æ ‡"""
        maa_keys = [k for k in self.metrics.keys() if 'generator' in k or 'discriminator' in k]
        if not maa_keys:
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle(f'{self.experiment_name} - MAA Metrics', fontsize=16, fontweight='bold')
        
        # ç”Ÿæˆå™¨å‡†ç¡®ç‡
        gen_keys = [k for k in maa_keys if 'generator' in k]
        if gen_keys:
            ax = axes[0, 0]
            for gen_key in gen_keys:
                data = self.metrics[gen_key]
                epochs = [d['epoch'] for d in data]
                values = [d['value'] for d in data]
                ax.plot(epochs, values, label=gen_key, linewidth=2, marker='o', markersize=3)
            ax.set_title('Generator Accuracy', fontweight='bold')
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Generator Accuracy')
            ax.legend()
            ax.grid(True, alpha=0.3)
            ax.set_ylim([0, 1])
        
        # åˆ¤åˆ«å™¨å‡†ç¡®ç‡
        disc_keys = [k for k in maa_keys if 'discriminator' in k]
        if disc_keys:
            ax = axes[0, 1]
            for disc_key in disc_keys:
                data = self.metrics[disc_key]
                epochs = [d['epoch'] for d in data]
                values = [d['value'] for d in data]
                ax.plot(epochs, values, label=disc_key, linewidth=2, marker='s', markersize=3)
            ax.set_title('Discriminator Accuracy', fontweight='bold')
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Discriminator Accuracy')
            ax.legend()
            ax.grid(True, alpha=0.3)
            ax.set_ylim([0, 1])
        
        # ç”Ÿæˆå™¨vsåˆ¤åˆ«å™¨å¯¹æŠ—
        if gen_keys and disc_keys:
            ax = axes[1, 0]
            gen_data = self.metrics[gen_keys[0]]
            disc_data = self.metrics[disc_keys[0]]
            
            gen_epochs = [d['epoch'] for d in gen_data]
            gen_values = [d['value'] for d in gen_data]
            disc_epochs = [d['epoch'] for d in disc_data]
            disc_values = [d['value'] for d in disc_data]
            
            ax.plot(gen_epochs, gen_values, label='Generator', linewidth=2, color='blue')
            ax.plot(disc_epochs, disc_values, label='Discriminator', linewidth=2, color='red')
            ax.axhline(y=0.5, color='green', linestyle='--', alpha=0.7, label='Balance Point')
            ax.set_title('Generator vs Discriminator', fontweight='bold')
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Accuracy')
            ax.legend()
            ax.grid(True, alpha=0.3)
            ax.set_ylim([0, 1])
        
        # MAAæ”¶æ•›åˆ†æ
        ax = axes[1, 1]
        if gen_keys and disc_keys:
            gen_data = self.metrics[gen_keys[0]]
            disc_data = self.metrics[disc_keys[0]]
            
            # è®¡ç®—å¯¹æŠ—å¹³è¡¡åº¦ (æ¥è¿‘0.5è¡¨ç¤ºå¹³è¡¡)
            balance_scores = []
            for gen_point, disc_point in zip(gen_data, disc_data):
                if gen_point['epoch'] == disc_point['epoch']:
                    balance = abs(gen_point['value'] - 0.5) + abs(disc_point['value'] - 0.5)
                    balance_scores.append({'epoch': gen_point['epoch'], 'balance': balance})
            
            if balance_scores:
                epochs = [b['epoch'] for b in balance_scores]
                balances = [b['balance'] for b in balance_scores]
                ax.plot(epochs, balances, linewidth=2, color='purple', marker='o', markersize=3)
                ax.set_title('MAA Adversarial Balance', fontweight='bold')
                ax.set_xlabel('Epoch')
                # æ ¹æ®å­—ä½“æ”¯æŒæƒ…å†µé€‰æ‹©æ ‡ç­¾
                if hasattr(self, '_use_english_labels') and self._use_english_labels:
                    ax.set_ylabel('Imbalance Score (lower is better)')
                else:
                    ax.set_ylabel('ä¸å¹³è¡¡åº¦ (è¶Šå°è¶Šå¥½)')
                ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(plot_dir, f'{self.get_file_prefix()}_maa_metrics.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_training_stats(self, plot_dir):
        """ç»˜åˆ¶è®­ç»ƒç»Ÿè®¡ä¿¡æ¯"""
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        fig.suptitle(f'{self.experiment_name} - Training Statistics', fontsize=16, fontweight='bold')
        
        # å­¦ä¹ ç‡å˜åŒ–
        ax1 = axes[0]
        if self.learning_rates and len(self.learning_rates) > 0:
            epochs = list(range(len(self.learning_rates)))
            ax1.plot(epochs, self.learning_rates, linewidth=2, color='orange', marker='o', markersize=3)
            ax1.set_title('Learning Rate Changes', fontweight='bold')
            ax1.set_xlabel('Epoch')
            ax1.set_ylabel('Learning Rate')
            ax1.grid(True, alpha=0.3)
            if max(self.learning_rates) / min(self.learning_rates) > 10:  # å¤§èŒƒå›´å˜åŒ–æ—¶ä½¿ç”¨å¯¹æ•°åæ ‡
                ax1.set_yscale('log')
        else:
            # å¦‚æœæ²¡æœ‰å­¦ä¹ ç‡æ•°æ®ï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
            ax1.text(0.5, 0.5, 'No Learning Rate Data\nRecorded', ha='center', va='center', 
                    transform=ax1.transAxes, fontsize=12, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
            ax1.set_title('Learning Rate Changes', fontweight='bold')
            ax1.set_xlabel('Epoch')
            ax1.set_ylabel('Learning Rate')
            ax1.grid(True, alpha=0.3)
        
        # è®­ç»ƒæ—¶é—´
        ax2 = axes[1]
        if self.epoch_times and len(self.epoch_times) > 0:
            epochs = list(range(len(self.epoch_times)))
            ax2.plot(epochs, self.epoch_times, linewidth=2, color='green', marker='s', markersize=3)
            ax2.set_title('Training Time per Epoch', fontweight='bold')
            ax2.set_xlabel('Epoch')
            ax2.set_ylabel('Time (seconds)')
            ax2.grid(True, alpha=0.3)
            
            # æ·»åŠ å¹³å‡æ—¶é—´çº¿
            if len(self.epoch_times) > 1:
                avg_time = np.mean(self.epoch_times)
                ax2.axhline(y=avg_time, color='red', linestyle='--', alpha=0.7, 
                          label=f'Average: {avg_time:.1f}s')
                ax2.legend()
        else:
            # å¦‚æœæ²¡æœ‰æ—¶é—´æ•°æ®ï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
            ax2.text(0.5, 0.5, 'No Training Time Data\nRecorded', ha='center', va='center', 
                    transform=ax2.transAxes, fontsize=12, bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
            ax2.set_title('Training Time per Epoch', fontweight='bold')
            ax2.set_xlabel('Epoch')
            ax2.set_ylabel('Time (seconds)')
            ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(plot_dir, f'{self.get_file_prefix()}_training_stats.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_performance_radar(self, ax):
        """ç»˜åˆ¶æ€§èƒ½é›·è¾¾å›¾"""
        try:
            # è·å–æœ€æ–°çš„æ€§èƒ½æŒ‡æ ‡
            metrics_to_plot = ['correlation', 'sharpe_ratio', 'generator_accuracy', 'discriminator_accuracy']
            labels = ['Correlation', 'Sharpe Ratio', 'Generator Acc', 'Discriminator Acc']
            values = []
            available_metrics = []
            available_labels = []
            
            for i, metric in enumerate(metrics_to_plot):
                metric_keys = [k for k in self.metrics.keys() if metric in k and 'val' in k]
                if not metric_keys:
                    metric_keys = [k for k in self.metrics.keys() if metric in k]
                
                if metric_keys:
                    data = self.metrics[metric_keys[0]]
                    if data:
                        latest_value = data[-1]['value']
                        # æ ‡å‡†åŒ–åˆ°0-1èŒƒå›´
                        if metric == 'correlation':
                            normalized_value = (latest_value + 1) / 2  # -1åˆ°1æ˜ å°„åˆ°0-1
                        elif metric == 'sharpe_ratio':
                            normalized_value = max(0, min(1, (latest_value + 2) / 4))  # -2åˆ°2æ˜ å°„åˆ°0-1
                        else:
                            normalized_value = max(0, min(1, latest_value))
                        
                        values.append(normalized_value)
                        available_metrics.append(metric)
                        available_labels.append(labels[i])
            
            if len(values) >= 3:  # è‡³å°‘éœ€è¦3ä¸ªæŒ‡æ ‡æ‰èƒ½ç”»é›·è¾¾å›¾
                # ç»˜åˆ¶é›·è¾¾å›¾
                angles = np.linspace(0, 2 * np.pi, len(available_labels), endpoint=False)
                values_closed = values + [values[0]]  # é—­åˆ
                angles_closed = np.concatenate((angles, [angles[0]]))
                
                # è®¾ç½®ä¸ºæåæ ‡
                ax = plt.subplot(111, projection='polar')
                ax.plot(angles_closed, values_closed, 'o-', linewidth=2, color='blue', markersize=6)
                ax.fill(angles_closed, values_closed, alpha=0.25, color='blue')
                ax.set_thetagrids(angles * 180/np.pi, available_labels)
                ax.set_ylim(0, 1)
                ax.set_title('Comprehensive Performance Radar', fontweight='bold', pad=20)
                ax.grid(True)
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for angle, value, label in zip(angles, values, available_labels):
                    ax.text(angle, value + 0.1, f'{value:.2f}', ha='center', va='center', fontsize=8)
                    
            elif len(values) > 0:
                # å¦‚æœæŒ‡æ ‡ä¸è¶³3ä¸ªï¼Œæ˜¾ç¤ºæŸ±çŠ¶å›¾
                ax.bar(available_labels, values, color='skyblue', alpha=0.7)
                ax.set_ylim(0, 1)
                ax.set_title('Performance Metrics Comparison', fontweight='bold')
                ax.grid(True, alpha=0.3)
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for i, (label, value) in enumerate(zip(available_labels, values)):
                    ax.text(i, value + 0.02, f'{value:.2f}', ha='center', va='bottom')
            else:
                ax.text(0.5, 0.5, 'No performance data\nUnable to generate chart', ha='center', va='center', transform=ax.transAxes)
                ax.set_title('Comprehensive Performance Radar', fontweight='bold')
                
        except Exception as e:
            print(f"âš ï¸ Radar chart generation failed: {str(e)}")
            ax.text(0.5, 0.5, f'Radar chart generation failed\n{str(e)}', ha='center', va='center', transform=ax.transAxes)
            ax.set_title('Comprehensive Performance Radar', fontweight='bold')
    
    def _plot_comprehensive_comparison(self, plot_dir):
        """ç»˜åˆ¶ç»¼åˆå¯¹æ¯”å›¾"""
        fig, ax = plt.subplots(figsize=(12, 8))
        fig.suptitle(f'{self.experiment_name} - Comprehensive Training Progress', fontsize=16, fontweight='bold')
        
        # æ”¶é›†æ‰€æœ‰å…³é”®æŒ‡æ ‡
        key_metrics = []
        
        # ä¸»è¦æŸå¤±
        train_loss_keys = [k for k in self.metrics.keys() if 'train' in k and 'loss' in k]
        if train_loss_keys:
            main_loss_key = train_loss_keys[0]
            data = self.metrics[main_loss_key]
            epochs = [d['epoch'] for d in data]
            values = [d['value'] for d in data]
            # æ ‡å‡†åŒ–æŸå¤±ï¼ˆåè½¬ï¼Œå› ä¸ºæŸå¤±è¶Šå°è¶Šå¥½ï¼‰
            if values:
                max_val = max(values)
                if max_val > 0:
                    normalized_values = [1 - (v / max_val) for v in values]
                    ax.plot(epochs, normalized_values, label='Training Loss (Normalized)', linewidth=2)
        
        # ç›¸å…³æ€§
        corr_keys = [k for k in self.metrics.keys() if 'correlation' in k and 'val' in k]
        if not corr_keys:
            corr_keys = [k for k in self.metrics.keys() if 'correlation' in k]
        if corr_keys:
            data = self.metrics[corr_keys[0]]
            epochs = [d['epoch'] for d in data]
            values = [d['value'] for d in data]
            # æ ‡å‡†åŒ–ç›¸å…³æ€§ï¼ˆ-1åˆ°1æ˜ å°„åˆ°0-1ï¼‰
            normalized_values = [(v + 1) / 2 for v in values]
            ax.plot(epochs, normalized_values, label='Prediction Correlation', linewidth=2)
        
        # ç”Ÿæˆå™¨å‡†ç¡®ç‡
        gen_keys = [k for k in self.metrics.keys() if 'generator_accuracy' in k]
        if gen_keys:
            data = self.metrics[gen_keys[0]]
            epochs = [d['epoch'] for d in data]
            values = [d['value'] for d in data]
            ax.plot(epochs, values, label='Generator Accuracy', linewidth=2)
        
        # éªŒè¯å‡†ç¡®ç‡æˆ–MSE
        val_acc_keys = [k for k in self.metrics.keys() if 'val' in k and ('accuracy' in k or 'mse' in k)]
        if val_acc_keys:
            data = self.metrics[val_acc_keys[0]]
            epochs = [d['epoch'] for d in data]
            values = [d['value'] for d in data]
            if 'accuracy' in val_acc_keys[0]:
                ax.plot(epochs, values, label='Validation Accuracy', linewidth=2)
            else:  # MSE - éœ€è¦åè½¬
                if values:
                    max_val = max(values)
                    if max_val > 0:
                        normalized_values = [1 - (v / max_val) for v in values]
                        ax.plot(epochs, normalized_values, label='Validation MSE (Normalized)', linewidth=2)
        
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Normalized Metric Value')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_ylim([0, 1])
        
        # æ·»åŠ æ–‡æœ¬è¯´æ˜
        ax.text(0.02, 0.98, 'All metrics normalized to 0-1 range\nHigher values indicate better performance', 
                transform=ax.transAxes, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        
        plt.tight_layout()
        plt.savefig(os.path.join(plot_dir, f'{self.get_file_prefix()}_comprehensive.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def generate_training_report(self):
        """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
        report_path = os.path.join(self.save_dir, f"{self.experiment_name}_training_report.md")
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"# {self.experiment_name} è®­ç»ƒæŠ¥å‘Š\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # è®­ç»ƒæ¦‚å†µ
            f.write("## è®­ç»ƒæ¦‚å†µ\n\n")
            if self.epoch_times:
                f.write(f"- è®­ç»ƒè½®æ•°: {len(self.epoch_times)}\n")
                f.write(f"- æ€»è®­ç»ƒæ—¶é—´: {sum(self.epoch_times):.1f} ç§’\n")
                f.write(f"- å¹³å‡æ¯è½®æ—¶é—´: {np.mean(self.epoch_times):.1f} ç§’\n")
            
            # æ€§èƒ½æŒ‡æ ‡
            f.write("\n## æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡\n\n")
            for metric_name, data in self.metrics.items():
                if data:
                    latest_value = data[-1]['value']
                    f.write(f"- {metric_name}: {latest_value:.6f}\n")
            
            # è®­ç»ƒå»ºè®®
            f.write("\n## è®­ç»ƒåˆ†æä¸å»ºè®®\n\n")
            
            # åˆ†ææŸå¤±æ”¶æ•›
            train_loss_keys = [k for k in self.metrics.keys() if 'train' in k and 'loss' in k]
            if train_loss_keys:
                loss_data = self.metrics[train_loss_keys[0]]
                if len(loss_data) > 5:
                    recent_losses = [d['value'] for d in loss_data[-5:]]
                    early_losses = [d['value'] for d in loss_data[:5]]
                    improvement = (np.mean(early_losses) - np.mean(recent_losses)) / np.mean(early_losses)
                    
                    if improvement > 0.1:
                        f.write("âœ… æŸå¤±æ”¶æ•›è‰¯å¥½ï¼Œæ¨¡å‹æ­£åœ¨å­¦ä¹ \n")
                    elif improvement > 0.01:
                        f.write("âš ï¸ æŸå¤±ä¸‹é™ç¼“æ…¢ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å­¦ä¹ ç‡\n")
                    else:
                        f.write("âŒ æŸå¤±åŸºæœ¬ä¸å˜ï¼Œå»ºè®®æ£€æŸ¥æ¨¡å‹æ¶æ„æˆ–æ•°æ®\n")
            
            # åˆ†æç›¸å…³æ€§
            corr_keys = [k for k in self.metrics.keys() if 'correlation' in k]
            if corr_keys:
                corr_data = self.metrics[corr_keys[0]]
                if corr_data:
                    latest_corr = corr_data[-1]['value']
                    if latest_corr > 0.7:
                        f.write("âœ… é¢„æµ‹ç›¸å…³æ€§å¾ˆé«˜ï¼Œæ¨¡å‹æ•ˆæœä¼˜ç§€\n")
                    elif latest_corr > 0.3:
                        f.write("âš ï¸ é¢„æµ‹ç›¸å…³æ€§ä¸­ç­‰ï¼Œæœ‰ä¼˜åŒ–ç©ºé—´\n")
                    else:
                        f.write("âŒ é¢„æµ‹ç›¸å…³æ€§è¾ƒä½ï¼Œéœ€è¦æ¨¡å‹ä¼˜åŒ–\n")
            
            # åˆ†æMAAå¹³è¡¡
            gen_keys = [k for k in self.metrics.keys() if 'generator_accuracy' in k]
            disc_keys = [k for k in self.metrics.keys() if 'discriminator_accuracy' in k]
            if gen_keys and disc_keys:
                gen_acc = self.metrics[gen_keys[0]][-1]['value'] if self.metrics[gen_keys[0]] else 0
                disc_acc = self.metrics[disc_keys[0]][-1]['value'] if self.metrics[disc_keys[0]] else 0
                
                balance = abs(gen_acc - disc_acc)
                if balance < 0.1:
                    f.write("âœ… MAAå¯¹æŠ—å¹³è¡¡è‰¯å¥½\n")
                elif balance < 0.3:
                    f.write("âš ï¸ MAAå¯¹æŠ—ç•¥æœ‰ä¸å¹³è¡¡\n")
                else:
                    f.write("âŒ MAAå¯¹æŠ—ä¸¥é‡ä¸å¹³è¡¡ï¼Œéœ€è¦è°ƒæ•´\n")
        
        print(f"ğŸ“‹ è®­ç»ƒæŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return report_path


def calculate_correlation(pred, true):
    """è®¡ç®—é¢„æµ‹ä¸çœŸå®å€¼çš„ç›¸å…³æ€§"""
    if len(pred) != len(true) or len(pred) == 0:
        return 0.0
    
    pred_tensor = torch.tensor(pred, dtype=torch.float32)
    true_tensor = torch.tensor(true, dtype=torch.float32)
    
    # ç§»é™¤NaNå€¼
    mask = ~(torch.isnan(pred_tensor) | torch.isnan(true_tensor))
    if mask.sum() < 2:
        return 0.0
    
    pred_clean = pred_tensor[mask]
    true_clean = true_tensor[mask]
    
    # è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°
    pred_mean = pred_clean.mean()
    true_mean = true_clean.mean()
    
    numerator = ((pred_clean - pred_mean) * (true_clean - true_mean)).sum()
    pred_std = ((pred_clean - pred_mean) ** 2).sum().sqrt()
    true_std = ((true_clean - true_mean) ** 2).sum().sqrt()
    
    if pred_std == 0 or true_std == 0:
        return 0.0
    
    correlation = numerator / (pred_std * true_std)
    return float(correlation.item())


def calculate_sharpe_ratio(returns, risk_free_rate=0.0):
    """è®¡ç®—å¤æ™®æ¯”ç‡"""
    if len(returns) == 0:
        return 0.0
    
    returns_tensor = torch.tensor(returns, dtype=torch.float32)
    mask = ~torch.isnan(returns_tensor)
    
    if mask.sum() < 2:
        return 0.0
    
    clean_returns = returns_tensor[mask]
    excess_returns = clean_returns - risk_free_rate
    
    if excess_returns.std() == 0:
        return 0.0
    
    sharpe = excess_returns.mean() / excess_returns.std() * np.sqrt(252)  # å¹´åŒ–
    return float(sharpe.item())


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºç›‘æ§å™¨
    monitor = TrainingMonitor("test_experiment")
    
    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    for epoch in range(50):
        monitor.start_epoch()
        
        # æ¨¡æ‹Ÿå„ç§æŒ‡æ ‡
        train_loss = 1.0 * np.exp(-epoch * 0.1) + np.random.normal(0, 0.1)
        val_loss = 1.2 * np.exp(-epoch * 0.08) + np.random.normal(0, 0.1)
        
        correlation = min(0.9, epoch * 0.02 + np.random.normal(0, 0.05))
        gen_acc = 0.5 + 0.3 * np.sin(epoch * 0.2) + np.random.normal(0, 0.02)
        disc_acc = 0.5 + 0.3 * np.cos(epoch * 0.2) + np.random.normal(0, 0.02)
        
        # è®°å½•æŒ‡æ ‡
        monitor.log_loss('train', 'total_loss', train_loss, epoch)
        monitor.log_loss('val', 'total_loss', val_loss, epoch)
        monitor.log_correlation('val', correlation, epoch)
        monitor.log_maa_metrics('train', gen_acc, disc_acc, epoch)
        
        monitor.end_epoch(epoch)
        
        # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´
        import time
        time.sleep(0.01)
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    monitor.generate_training_report()
    print("[INFO] è®­ç»ƒç›‘æ§ç¤ºä¾‹å®Œæˆï¼")
